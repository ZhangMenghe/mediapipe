# MediaPipe ear landmark localization subgraph.

type: "earLandmarkSubgraph"

input_stream: "IMAGE_GPU:input_video"
input_stream: "NORM_RECT:ear_rect"
output_stream: "LANDMARKS:ear_landmarks"
output_stream: "NORM_RECT:ear_rect_fine_crop"
output_stream: "PRESENCE:ear_presence"
#output_stream: "PRESENCE_SCORE:ear_presence_score"
#output_stream: "earEDNESS:earedness"

# Crops the rectangle that contains a ear from the input image.
node: {
  calculator: "ImageCroppingCalculator"
  input_stream: "IMAGE_GPU:input_video"
  input_stream: "NORM_RECT:ear_rect"
  output_stream: "IMAGE_GPU:ear_image"
  node_options: {
    [type.googleapis.com/mediapipe.ImageCroppingCalculatorOptions] {
      border_mode: BORDER_REPLICATE
    }
  }
}
## For debug only: output cropped rect of rough ear
node: {
  calculator: "GpuBufferToImageFrameCalculator"
  input_stream: "ear_image"
  output_stream: "ear_image_cpu"
}
node: {
  calculator: "FineCropEarCpuCalculator"
  input_stream: "ear_image_cpu"
  input_stream: "NORM_RECT:ear_rect"
  output_stream: "fine_cropped_cpu"
  output_stream: "NORM_RECT:ear_rect_fine_crop"
  output_stream: "FLAG:ear_presence"
}
node: {
  calculator: "EarNormalizeCalculator"
  input_stream: "fine_cropped_cpu"
  output_stream: "normalized_cpu"
}

node:{
  calculator: "MakeSureEarLeftSubgraph"
  input_stream: "IMAGE:normalized_cpu"
  output_stream: "IMAGE:normalized_cpu_left"
  output_stream: "EAR_FLIPPED:ear_flipped"
}

node: {
  calculator: "ImageFrameToGpuBufferCalculator"
  input_stream: "fine_cropped_cpu"
  output_stream: "fine_cropped_gpu"
}

# node: {
#   calculator: "SaveCPUImageCalculator"
#   input_stream: "ear_image_cpu"
# }

# Transforms the input image on GPU to a 224x224 image. To scale the input
# image, the scale_mode option is set to FIT to preserve the aspect ratio,
# resulting in potential letterboxing in the transformed image.
node: {
  calculator: "ImageTransformationCalculator"
  # input_stream: "IMAGE_GPU:ear_image"
  input_stream: "IMAGE_GPU:fine_cropped_gpu"
  output_stream: "IMAGE_GPU:transformed_ear_image"
  #output_stream: "LETTERBOX_PADDING:letterbox_padding"
  node_options: {
    [type.googleapis.com/mediapipe.ImageTransformationCalculatorOptions] {
      output_width: 224
      output_height: 224
      scale_mode: FIT
    }
  }
}

# Generates a single side packet containing a TensorFlow Lite op resolver that
# supports custom ops needed by the model used in this graph.
node {
  calculator: "TfLiteCustomOpResolverCalculator"
  output_side_packet: "op_resolver"
  node_options: {
    [type.googleapis.com/mediapipe.TfLiteCustomOpResolverCalculatorOptions] {
      use_gpu: true
    }
  }
}

# Converts the transformed input image on GPU into an image tensor stored as a
# TfLiteTensor.
node {
  calculator: "TfLiteConverterCalculator"
  input_stream: "IMAGE_GPU:transformed_ear_image"
  output_stream: "TENSORS_GPU:image_tensor"
  node_options: {
    [type.googleapis.com/mediapipe.TfLiteConverterCalculatorOptions] {
      zero_center: false
    }
  }
}

# Runs a TensorFlow Lite model on GPU that takes an image tensor and outputs a
# vector of tensors representing, for instance, detection boxes/keypoints and
# scores.
node {
  calculator: "TfLiteInferenceCalculator"
  input_stream: "TENSORS_GPU:image_tensor"
  output_stream: "TENSORS:output_tensors"
  input_side_packet: "CUSTOM_OP_RESOLVER:op_resolver"
  node_options: {
    [type.googleapis.com/mediapipe.TfLiteInferenceCalculatorOptions] {
      model_path: "mediapipe/models/ear_landmarks.tflite"
      use_gpu: true
    }
  }
}

# Splits a vector of tensors into multiple vectors.
#node {
#  calculator: "SplitTfLiteTensorVectorCalculator"
#  input_stream: "output_tensors"
#  output_stream: "landmark_tensors"
  #output_stream: "ear_flag_tensor"
  #output_stream: "earedness_tensor"
#  node_options: {
#    [type.googleapis.com/mediapipe.SplitVectorCalculatorOptions] {
#      ranges: { begin: 0 end: 1 }
#      ranges: { begin: 1 end: 2 }
#      ranges: { begin: 2 end: 3 }
#    }
#  }
#}

# Converts the ear-flag tensor into a float that represents the confidence
# score of ear presence.
#node {
#  calculator: "TfLiteTensorsToFloatsCalculator"
#  input_stream: "TENSORS:ear_flag_tensor"
#  output_stream: "FLOAT:ear_presence_score"
#}

# Converts the earedness tensor into a float as the score of the earedness
# binary classifciation.
#node {
#  calculator: "TfLiteTensorsToClassificationCalculator"
#  input_stream: "TENSORS:earedness_tensor"
#  output_stream: "CLASSIFICATIONS:earedness"
#  node_options: {
#    [type.googleapis.com/mediapipe.TfLiteTensorsToClassificationCalculatorOptions] {
#      top_k: 1
#      label_map_path: "mediapipe/models/earedness.txt"
#      binary_classification: true
#    }
#  }
#}

# Applies a threshold to the confidence score to determine whether a ear is
# present.
#node {
#  calculator: "ThresholdingCalculator"
#  input_stream: "FLOAT:ear_presence_score"
#  output_stream: "FLAG:ear_presence"
#  node_options: {
#    [type.googleapis.com/mediapipe.ThresholdingCalculatorOptions] {
#      threshold: 0.1
#    }
#  }
#}

# Decodes the landmark tensors into a list of landmarks, where the landmark
# coordinates are normalized by the size of the input image to the model.
node {
  calculator: "TfLiteTensorsToLandmarksCalculator"
  input_stream: "TENSORS:output_tensors"
  output_stream: "NORM_LANDMARKS:landmarks"
  node_options: {
    [type.googleapis.com/mediapipe.TfLiteTensorsToLandmarksCalculatorOptions] {
      num_landmarks: 55
      input_image_width: 1
      input_image_height: 1
      # The additional scaling factor is used to account for the Z coordinate
      # distribution in the training data.
      normalize_z: 0.4
      flip_vertically: true
      chunk_tensor: true
    }
  }
}

# Adjusts landmarks (already normalized to [0.f, 1.f]) on the letterboxed ear
# image (after image transformation with the FIT scale mode) to the
# corresponding locations on the same image with the letterbox removed (ear
# image before image transformation).
#node {
#  calculator: "LandmarkLetterboxRemovalCalculator"
#  input_stream: "LANDMARKS:landmarks"
#  input_stream: "LETTERBOX_PADDING:letterbox_padding"
#  output_stream: "LANDMARKS:scaled_landmarks"
#}

# Projects the landmarks from the cropped ear image to the corresponding
# locations on the full image before cropping (input to the graph).
node {
  calculator: "LandmarkProjectionCalculator"
  input_stream: "NORM_LANDMARKS:landmarks"
  input_stream: "NORM_RECT:ear_rect_fine_crop"
  output_stream: "NORM_LANDMARKS:ear_landmarks"
  node_options: {
    [type.googleapis.com/mediapipe.LandmarkProjectionCalculatorOptions]{
      ignore_rotation: true
    }
  }
}

# Extracts image size from the input images.
# node {
#  calculator: "ImagePropertiesCalculator"
#  input_stream: "IMAGE_GPU:input_video"
#  output_stream: "SIZE:image_size"
# }

# Extracts a subset of the ear landmarks that are relatively more stable across
# frames (e.g. comparing to finger tips) for computing the bounding box. The box
# will later be expanded to contain the entire ear. In this approach, it is
# more robust to drastically changing ear size.
# The landmarks extracted are: wrist, MCP/PIP of five fingers.
# node {
#   calculator: "SplitNormalizedLandmarkListCalculator"
#   input_stream: "ear_landmarks"
#   output_stream: "partial_landmarks"
#   node_options: {
#     [type.googleapis.com/mediapipe.SplitVectorCalculatorOptions] {
#       ranges: { begin: 0 end: 4 }
#       ranges: { begin: 5 end: 7 }
#       ranges: { begin: 9 end: 11 }
#       ranges: { begin: 13 end: 15 }
#       ranges: { begin: 17 end: 19 }
#       combine_outputs: true
#     }
#   }
# }

# Converts ear landmarks to a detection that tightly encloses all landmarks.
# node {
#   calculator: "LandmarksToDetectionCalculator"
#   input_stream: "NORM_LANDMARKS:partial_landmarks"
#   output_stream: "DETECTION:ear_detection"
# }

# # Converts the ear detection into a rectangle (normalized by image size)
# # that encloses the ear.
# node {
#   calculator: "EarLandmarksToRectsCalculator"
#   input_stream: "LANDMARKS:ear_landmarks"
#   output_stream: "NORM_RECT_EAR:ear_rect_from_landmarks"
#   output_stream: "FLAG:ear_presence"
# }

# # Expands the ear rectangle so that the box contains the entire ear and it's
# # big enough so that it's likely to still contain the ear even with some motion
# # in the next video frame .
# node {
#   calculator: "RectTransformationCalculator"
#   input_stream: "NORM_RECT:ear_rect_from_landmarks"
#   input_stream: "IMAGE_SIZE:image_size"
#   output_stream: "ear_rect_for_next_frame"
#   node_options: {
#     [type.googleapis.com/mediapipe.RectTransformationCalculatorOptions] {
#       scale_x: 2.1
#       scale_y: 2.1
#       shift_y: -0.1
#       square_long: true
#     }
#   }
# }
