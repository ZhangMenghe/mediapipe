input_stream: "input_video"
output_stream: "output_video"

node {
  calculator: "FlowLimiterCalculator"
  input_stream: "input_video"
  input_stream: "FINISHED:slam_output"
  input_stream_info: {
    tag_index: "FINISHED"
    back_edge: true
  }
  output_stream: "throttled_input_video"
}

# Transforms the input image on GPU to a 256x256 image. To scale the input
# image, the scale_mode option is set to FIT to preserve the aspect ratio,
# resulting in potential letterboxing in the transformed image.
node: {
  calculator: "ImageTransformationCalculator"
  # input_stream: "IMAGE_GPU:input_video"
  input_stream: "IMAGE_GPU:throttled_input_video"
  output_stream: "IMAGE_GPU:transformed_input_video"

  #output_stream: "CAMERA_POSE:frame_cam_pose_input"
  #output_stream: "IMAGE_ALIGN:transformed_input_video_cpu"
  #output_stream: "LETTERBOX_PADDING:letterbox_padding"
  # node_options: {
  #   [type.googleapis.com/mediapipe.ImageTransformationCalculatorOptions] {
  #     output_width: 752
  #     output_height: 480
  #     scale_mode: FIT
  #   }
  # }
}

# Converts RGB images into luminance images, still stored in RGB format.
node: {
  calculator: "LuminanceCalculator"
  input_stream: "transformed_input_video"
  #output_stream:"output_video"
  output_stream: "transformed_luminance"
}

# Fuse cpu RGB images to orb calculator
node: {
  calculator: "OrbSLAMCalculator"
  #input_stream: "CAMERA_POSE:frame_cam_pose_input"
  input_stream: "IMAGE:transformed_luminance_cpu"
  output_stream:"SLAM_OUT:slam_output"
  #output_stream: "CAMERA_POSE:frame_cam_pose_output"
  #output_stream:"KEY_POINTS:key_points"
  options {
    [mediapipe.OrbSLAMCalculatorOptions.ext] {
      voc_path: "../data/slam/vocabulary.txt"
      # voc_path: "../data/slam/seevee.yml"
      # camera_path: "../data/slam/camera.yaml"
      camera_path: "../data/slam/Microsoft_webcam.yaml"

    }
  }
}

node: {
  calculator: "MergeSLAMCalculator"
  #input_stream:"CAMERA_POSE:frame_cam_pose_output"
  #input_stream:"KEY_POINTS:key_points"
  input_stream:"SLAM_OUT:slam_output"
  input_stream:"IMAGE_GPU:transformed_input_video"
  output_stream:"IMAGE_GPU:output_video"
  options {
    [mediapipe.glShaderHelperOptions.ext] {
      shader_files{
        shader_name:"DICOM_RAYCAST"
        vs_path : "mediapipe/res/shaders/raycastVolume.vert"
        frag_path : "mediapipe/res/shaders/raycastVolume.frag"
        geom_path : "mediapipe/res/shaders/raycastVolume.glsl"
      }
      # shader_files{
      #   shader_name:"point"
      #   vs_path : "mediapipe/res/shaders/raycastVolume.vert"
      #   frag_path : "mediapipe/res/shaders/raycastVolume.frag"
      #   geom_path : "mediapipe/res/shaders/raycastVolume.glsl"
      # }

    }
  }
}

# Transfers the input image from GPU to CPU memory for the purpose of
# demonstrating a CPU-based pipeline. Note that the input image on GPU has the
# origin defined at the bottom-left corner (OpenGL convention). As a result,
# the transferred image on CPU also shares the same representation.
node: {
  calculator: "GpuBufferToImageFrameCalculator"
  input_stream: "transformed_luminance"
  output_stream: "transformed_luminance_cpu"
}
